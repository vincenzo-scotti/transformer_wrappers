{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Speech transformer "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42dd89abb631d1e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b7de2f2910c7a77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36658f319f21ed06"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('~/Projects/transformer_wrappers/src')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T15:34:11.667016Z",
     "start_time": "2024-10-10T15:34:11.665158Z"
    }
   },
   "id": "3ce5db8a5a94b70f",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:40.804311Z",
     "start_time": "2024-10-11T16:29:40.132099Z"
    }
   },
   "id": "dad5c72c42686d67",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincenzoscotti/anaconda3/envs/trwrap/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:40.951193Z",
     "start_time": "2024-10-11T16:29:40.805107Z"
    }
   },
   "id": "1da0d0b936e4c968",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformer_wrappers.wrappers import SpeechCausalLMWrapper"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:42.011008Z",
     "start_time": "2024-10-11T16:29:40.951721Z"
    }
   },
   "id": "2baf878f3b022d7a",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants and globals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67faf2489a3d75be"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "TOKEN = None  # HF Token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:42.013405Z",
     "start_time": "2024-10-11T16:29:42.011820Z"
    }
   },
   "id": "f69813390cefb01",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL = 'gpt2'  \n",
    "# MODEL = 'mistralai/Mistral-7B-Instruct-v0.3'  \n",
    "# MODEL = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "# MODEL = 'google/gemma-2-9b-it'\n",
    "MODEL_CONFIGS = {\n",
    "    'torch_dtype': torch.bfloat16,\n",
    "    'device_map': 'cpu',  # torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'token': TOKEN\n",
    "}\n",
    "TOKENIZER_CONFIGS = {'token': TOKEN, 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|audio|>']}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:42.015992Z",
     "start_time": "2024-10-11T16:29:42.013807Z"
    }
   },
   "id": "23bd06e783d5cb",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "QUANTIZATION_CONFIGS = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type='nf4', \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:42.018808Z",
     "start_time": "2024-10-11T16:29:42.016319Z"
    }
   },
   "id": "b0632824bc83333b",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincenzoscotti/anaconda3/envs/trwrap/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SpeechCausalLMWrapper.from_pretrained(\n",
    "    MODEL,\n",
    "    model_kwargs=MODEL_CONFIGS,\n",
    "    # quantization_configs=QUANTIZATION_CONFIGS,\n",
    "    tokenizer_kwargs=TOKENIZER_CONFIGS\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:43.710738Z",
     "start_time": "2024-10-11T16:29:42.019155Z"
    }
   },
   "id": "3e6f4622200bc799",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad9b56abef0327b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Ellipsis"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:43.714804Z",
     "start_time": "2024-10-11T16:29:43.711536Z"
    }
   },
   "id": "8f16202dca51ec68",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Speech recognition\n",
    "\n",
    "In this first example we show how to forward an input composed of text and audio to the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7dcbd053f3daf29"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = f'Transcribe the following audio clip:\\n{model.audio_token}\\n\\nTranscription:\\n\"In a hole in the ground there lived a hobbit.\"'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:43.717951Z",
     "start_time": "2024-10-11T16:29:43.716227Z"
    }
   },
   "id": "caf8525c5ed62f05",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "audio_file_path = '../audio.wav'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:43.720101Z",
     "start_time": "2024-10-11T16:29:43.718580Z"
    }
   },
   "id": "bd2427db585594c9",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_encoding = model.prepare_input(text, audio_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:44.031833Z",
     "start_time": "2024-10-11T16:29:43.720743Z"
    }
   },
   "id": "17955e75a9bd184",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 402])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoding['input_spectrograms'][0].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:29:44.040171Z",
     "start_time": "2024-10-11T16:29:44.032857Z"
    }
   },
   "id": "9e321bf389a8b2d7",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output = model.forward(**input_encoding)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:30:49.317361Z",
     "start_time": "2024-10-11T16:30:43.132482Z"
    }
   },
   "id": "408d2726c9989a5a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position_ids\n",
      "past_key_values\n",
      "batch_size\n",
      "prefix_length\n",
      "sequence_length\n",
      "cache_position\n",
      "dtype\n",
      "device\n",
      "speech_mask\n",
      "attention_mask\n",
      "add_attn_residual\n",
      "add_ffnn_residual\n",
      "use_cache\n",
      "output_attentions\n",
      "output_hidden_states\n",
      "return_intermediate_hidden_states\n",
      "return_attention_output\n",
      "return_feed_forward_up_proj_output\n",
      "return_feed_forward_gate_output\n",
      "return_feed_forward_inner_activations\n",
      "return_feed_forward_output\n",
      "output_hidden_state\n",
      "logits\n",
      "spectrograms\n",
      "modality_mask\n",
      "loss\n",
      "cache\n",
      "hidden_states\n",
      "attention_weights\n",
      "return_dict\n"
     ]
    }
   ],
   "source": [
    "for k in output:\n",
    "    print(k)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:30:53.540754Z",
     "start_time": "2024-10-11T16:30:53.538362Z"
    }
   },
   "id": "bb26fd7feb4ebfaa",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[-10.7500, -10.2500,   5.1875,  ...,   2.8125,   1.5625,  -3.0938],\n         [ -2.5312, -10.1875,   1.9609,  ...,   1.0625,  -3.2031,  -3.9219],\n         [ -5.4375,   4.4688,  -8.2500,  ...,   0.6172,  -4.5000,  -0.3613],\n         ...,\n         [  1.9297,  -7.7188, -11.8125,  ...,   0.1885,  -2.0781,  -2.0156],\n         [ -6.5938, -16.8750,  -0.0503,  ...,   0.4629,  -0.3027,   0.1143],\n         [  4.0000,  -1.1328,  12.3750,  ...,  -2.3281,  -2.0000,  -0.5820]],\n        dtype=torch.bfloat16, grad_fn=<SqueezeBackward1>)]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['spectrograms']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-11T16:31:07.613229Z",
     "start_time": "2024-10-11T16:31:07.610283Z"
    }
   },
   "id": "99eaecb37cba8a9f",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "daa7aa7b78278324"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
