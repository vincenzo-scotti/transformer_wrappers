{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Speech transformer "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42dd89abb631d1e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b7de2f2910c7a77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36658f319f21ed06"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append('~/Projects/transformer_wrappers/src')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:15.330344Z",
     "start_time": "2024-10-15T13:23:15.329100Z"
    }
   },
   "id": "3ce5db8a5a94b70f",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:15.919595Z",
     "start_time": "2024-10-15T13:23:15.345844Z"
    }
   },
   "id": "dad5c72c42686d67",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincenzoscotti/anaconda3/envs/trwrap/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from peft import LoraConfig"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:16.432800Z",
     "start_time": "2024-10-15T13:23:15.920361Z"
    }
   },
   "id": "1da0d0b936e4c968",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformer_wrappers.wrappers import SpeechCausalLMWrapper"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:16.952475Z",
     "start_time": "2024-10-15T13:23:16.433345Z"
    }
   },
   "id": "2baf878f3b022d7a",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants and globals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67faf2489a3d75be"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "TOKEN = None  # HF Token"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:16.954702Z",
     "start_time": "2024-10-15T13:23:16.953252Z"
    }
   },
   "id": "f69813390cefb01",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL = 'gpt2'  \n",
    "# MODEL = 'mistralai/Mistral-7B-Instruct-v0.3'  \n",
    "# MODEL = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "# MODEL = 'google/gemma-2-9b-it'\n",
    "MODEL_CONFIGS = {\n",
    "    'torch_dtype': torch.bfloat16,\n",
    "    'device_map': 'cpu',  # torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'token': TOKEN\n",
    "}\n",
    "TOKENIZER_CONFIGS = {'token': TOKEN, 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|audio|>']}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:16.957119Z",
     "start_time": "2024-10-15T13:23:16.955065Z"
    }
   },
   "id": "23bd06e783d5cb",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "QUANTIZATION_CONFIGS = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_use_double_quant=True, \n",
    "    bnb_4bit_quant_type='nf4', \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:16.959770Z",
     "start_time": "2024-10-15T13:23:16.957441Z"
    }
   },
   "id": "b0632824bc83333b",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "LORA_CONFIGS = LoraConfig(\n",
    "    target_modules='all-linear',\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=16,\n",
    "    bias='none',\n",
    "    task_type='CAUSAL_LM'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:16.961447Z",
     "start_time": "2024-10-15T13:23:16.960146Z"
    }
   },
   "id": "6dbebabb7e185b67",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincenzoscotti/anaconda3/envs/trwrap/lib/python3.12/site-packages/peft/tuners/lora/layer.py:861: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n",
      "/home/vincenzoscotti/anaconda3/envs/trwrap/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SpeechCausalLMWrapper.from_pretrained(\n",
    "    MODEL,\n",
    "    model_kwargs=MODEL_CONFIGS,\n",
    "    # quantization_configs=QUANTIZATION_CONFIGS,\n",
    "    lora_configs=LORA_CONFIGS,\n",
    "    tokenizer_kwargs=TOKENIZER_CONFIGS\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:17.744596Z",
     "start_time": "2024-10-15T13:23:16.961759Z"
    }
   },
   "id": "3e6f4622200bc799",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad9b56abef0327b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Ellipsis"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:17.748083Z",
     "start_time": "2024-10-15T13:23:17.745066Z"
    }
   },
   "id": "8f16202dca51ec68",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97f918b01e57fc80"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = f'Transcribe the following audio clip:\\n{model.audio_token}\\n\\nTranscription:\\n\"In a hole in the ground there lived a hobbit.\"'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:17.750754Z",
     "start_time": "2024-10-15T13:23:17.749095Z"
    }
   },
   "id": "caf8525c5ed62f05",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "audio_file_path = '../audio.wav'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:17.753049Z",
     "start_time": "2024-10-15T13:23:17.751069Z"
    }
   },
   "id": "bd2427db585594c9",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_encoding = model.prepare_input(text, audio_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.142303Z",
     "start_time": "2024-10-15T13:23:17.753375Z"
    }
   },
   "id": "17955e75a9bd184",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Forward\n",
    "\n",
    "In this first example we show how to forward an input composed of text and audio to the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7dcbd053f3daf29"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 128, 570])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_encoding['input_spectrograms'].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.144985Z",
     "start_time": "2024-10-15T13:23:18.142827Z"
    }
   },
   "id": "9e321bf389a8b2d7",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "output = model.forward(**input_encoding)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.217175Z",
     "start_time": "2024-10-15T13:23:18.145335Z"
    }
   },
   "id": "408d2726c9989a5a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 128, 570])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['spectrograms'].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.219806Z",
     "start_time": "2024-10-15T13:23:18.217686Z"
    }
   },
   "id": "736273b5305a3e3a",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "target_output = model.prepare_output(text, audio_file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.319132Z",
     "start_time": "2024-10-15T13:23:18.220229Z"
    }
   },
   "id": "882c13cf8d57566c",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 128, 570])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_output['target_spectrograms'].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.321308Z",
     "start_time": "2024-10-15T13:23:18.319556Z"
    }
   },
   "id": "402211a5f8f748e",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(3624.9373, grad_fn=<AddBackward0>),\n {'language_modelling_loss': tensor(20.1023, grad_fn=<NllLossBackward0>),\n  'spectrogram_generation_loss': tensor(3604.8350, grad_fn=<MseLossBackward0>)})"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = model._loss(\n",
    "    token_logits=output['logits'],\n",
    "    token_labels=target_output['token_labels'],\n",
    "    predicted_spectrograms=output['spectrograms'],\n",
    "    target_spectrograms=target_output['target_spectrograms']\n",
    ")\n",
    "loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.331653Z",
     "start_time": "2024-10-15T13:23:18.321680Z"
    }
   },
   "id": "bb26fd7feb4ebfaa",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([128, 402])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.post_process_spectrograms(input_encoding['input_spectrograms'], input_encoding['input_ids'])[0][0].size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.334059Z",
     "start_time": "2024-10-15T13:23:18.332088Z"
    }
   },
   "id": "4adf903ff9a40b65",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(128, 402)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.audio_processor.encode(audio_file_path).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.348167Z",
     "start_time": "2024-10-15T13:23:18.334510Z"
    }
   },
   "id": "424d3d70f74ce1da",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e95d908409dcc2da"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.enable_benchmarking()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.350958Z",
     "start_time": "2024-10-15T13:23:18.348584Z"
    }
   },
   "id": "128adfd9db3d097e",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The following `model_kwargs` are not used by the model: ['input_ids', 'attention_mask'] (note: typos in the generate arguments will also show up in this list)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m ids, specs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_encoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# ids, specs = model.generate(input_encoding.input_ids, max_new_tokens=4)\u001B[39;00m\n",
      "File \u001B[0;32m/tmp/pycharm_project_13/src/transformer_wrappers/wrappers/speech.py:662\u001B[0m, in \u001B[0;36mSpeechCausalLMWrapper.generate\u001B[0;34m(self, return_inner_states, *args, **kwargs)\u001B[0m\n\u001B[1;32m    660\u001B[0m generated_spectrograms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m()\n\u001B[1;32m    661\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m--> 662\u001B[0m generate_output \u001B[38;5;241m=\u001B[39m \u001B[43mPreTrainedModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    663\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerated_spectrograms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerated_spectrograms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    664\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    665\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    666\u001B[0m \u001B[38;5;66;03m# TODO: handle guided generation vs normal generation case\u001B[39;00m\n\u001B[1;32m    667\u001B[0m generated_spectrograms \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(generated_spectrograms, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/trwrap/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/trwrap/lib/python3.12/site-packages/transformers/generation/utils.py:1689\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001B[0m\n\u001B[1;32m   1687\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokenizer\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)  \u001B[38;5;66;03m# Pull this out first, we only use it for stopping criteria\u001B[39;00m\n\u001B[1;32m   1688\u001B[0m generation_config, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_generation_config(generation_config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1689\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_model_kwargs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1690\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_assistant(assistant_model)\n\u001B[1;32m   1692\u001B[0m \u001B[38;5;66;03m# 2. Set generation parameters if not already defined\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/trwrap/lib/python3.12/site-packages/transformers/generation/utils.py:1243\u001B[0m, in \u001B[0;36mGenerationMixin._validate_model_kwargs\u001B[0;34m(self, model_kwargs)\u001B[0m\n\u001B[1;32m   1240\u001B[0m         unused_model_args\u001B[38;5;241m.\u001B[39mappend(key)\n\u001B[1;32m   1242\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m unused_model_args:\n\u001B[0;32m-> 1243\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1244\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe following `model_kwargs` are not used by the model: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00munused_model_args\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (note: typos in the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1245\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m generate arguments will also show up in this list)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1246\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: The following `model_kwargs` are not used by the model: ['input_ids', 'attention_mask'] (note: typos in the generate arguments will also show up in this list)"
     ]
    }
   ],
   "source": [
    "ids, specs = model.generate(**input_encoding, max_new_tokens=4)\n",
    "# ids, specs = model.generate(input_encoding.input_ids, max_new_tokens=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-15T13:23:18.583263Z",
     "start_time": "2024-10-15T13:23:18.351580Z"
    }
   },
   "id": "8e538355112374cc",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import inspect\n",
    "set(inspect.signature(model.prepare_inputs_for_generation).parameters)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c279a97e59f8a398",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "set(inspect.signature(model.forward).parameters)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb5537f7a7543c57",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f1ccd7aaaf1c820"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
